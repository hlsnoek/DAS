*****
<a name="B3.A"></a>

#B3.A Grote Aantallen III ***

In deze opdracht gaan het eindresultaat van B2.A 'fitten' met de kleinste kwadraten methode. 

We hebben gezien dat er verband is tussen de grootte van onze steekproef en de onzekerheid op het bepaalde gemiddelde. Deze volgt de $$\sqrt{N}$$-[wet](/blok-2/wet-van-grote-aantallen). We gaan in deze opdracht een lineaire regressie (ofwel een fit) aan de data punten maken met behulp van de kleinste kwadraten methode. 

Download allereerst een nieuwe [DAS_DatasetGenerator.py](DAS_DatasetGenerator.py) en voer weer je studentnummer in. 

We gaan eerst datapunten fitten met gelijke fouten.
Met de volgende instructie kun je de datapunten opvragen: 

	inv_n_sqr,std_n,std_err = ds.GroteAantallenFitSetGenerator() 

De $$\text{inv_n_sqr}$$ punten zijn de waardes van $$1/\sqrt{N}$$ waarbij $$N$$ de grootte is van de steekproef zoals je die in B2.A hebt gedaan, $$\text{std_n}$$ is de onzekerheid $$\sigma_{\mu_n}$$ en $$\text{std_err}$$ zijn de onzekerheden op deze punten van $$\sigma_{\mu_n}$$. Voor deze dataset zijn ze allemaal gelijk, later in deze opdracht zullen we met meer reeele onzekerheden gaan werken. Maar voor het opzetten van de fit beginnen we met deze dataset.

> * Maak eerst een plotje waarbij je $$\text{inv_n_sqr}$$ tegen $$\text{std_n}$$ uitzet met de foutenvlaggen. 

Naar aanleiding van de $$\sqrt{N}$$-wet verwachten dat de relatie tussen $$N$$ en $$\sigma_{\mu_n}$$ er als volgt uitziet:<br>
<center>$${\displaystyle \sigma_{\mu_n} = \sigma/\sqrt{N}.}$$</center><br>

Dit geeft de volgende relatie tussen 
$$\text{inv_n_sqr}$$ en $$\text{std_n}$$:<br>

<center>$${\displaystyle \text{std_n} = s \cdot \text{std_n}.}$$</center><br>

De variable $$s$$ is nu de standaard deviatie van de originele verdeling van de massa van de kogels.

> * Vindt de meest optimale waarde van $$\sigma$$ door gebruik te maken van [de kleinste-kwadraten](/blok-3/de-kleinste-kwadraten-methode) methode. <br>
> **Tip 1:** Schrijf een loop die over verschillende waardes van $$m$$ loopt voor het optimalisatie process. Weet je zeker dat de juiste waarde van $$m$$  in het gebied ligt waar je probeert te optimaliseren?<br>
> **Tip2: ** Optimaliseer eerst je fit zonder gebruik te maken van de foutenvlaggen. Breidt daarna de functie uit door de methode te gebruiken met foutenvlaggen. Omdat de foutenvlaggen allemaal hetzelfde zijn hoort hier bijna hetzelfde resultaat uit te komen.  <br>
> * Welke waarde voor $$s$$ geeft de beste fit? <br>
> * Maak een grafiek met de datapunten, de foutenvlaggen en het fitresultaat. 

Met de functie:
	
	s_true = GroteAantallenStdTrue

Kun je de werkelijke waarde voor de geimuleerde waarde van $$s$$ terugvragen. 

> * Controleer dat de gefitte waarde van $$s$$ overeen komt met je uitkomst. Je verwacht altijd nog wel wat verschillen te zien. 

We gaan de $$\chi^2$$ uitrekenen van de geoptimaliseerde waarde van $$s$$. 
Schrijf hiervoor een functie die deze uitrekent. 

> * Wat is de $$\chi^2$$ voor de fit?

We gaan nu de fit uitvoeren met reeele onzekerheden op de punten. Deze datapunten genereer je met de volgende functie: 

	 inv_n_sqr,std_n,std_err = GroteAantallenStdGenerator()
 
> * Vindt nu de meest optimale waarde van $$\sigma$$ door gebruik te maken van de reeele foutenvlaggen. 
> * Wat is de beste waarde an $$\sigma$$?
> * Maak nu een grafiek met de datapunten, de foutenvlaggen en het fitresultaat voor de dataset met reeele foutenvlaggen.  
> * Wat is de $$\chi^2$$ voor de fit?
