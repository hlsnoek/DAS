\PassOptionsToPackage{unicode=true}{hyperref} % options for packages loaded elsewhere
\PassOptionsToPackage{hyphens}{url}
%
\documentclass[]{book}
\usepackage{lmodern}
\usepackage{amssymb,amsmath}
\usepackage{ifxetex,ifluatex}
\usepackage{fixltx2e} % provides \textsubscript
\ifnum 0\ifxetex 1\fi\ifluatex 1\fi=0 % if pdftex
  \usepackage[T1]{fontenc}
  \usepackage[utf8]{inputenc}
  \usepackage{textcomp} % provides euro and other symbols
\else % if luatex or xelatex
  \usepackage{unicode-math}
  \defaultfontfeatures{Ligatures=TeX,Scale=MatchLowercase}
\fi
% use upquote if available, for straight quotes in verbatim environments
\IfFileExists{upquote.sty}{\usepackage{upquote}}{}
% use microtype if available
\IfFileExists{microtype.sty}{%
\usepackage[]{microtype}
\UseMicrotypeSet[protrusion]{basicmath} % disable protrusion for tt fonts
}{}
\IfFileExists{parskip.sty}{%
\usepackage{parskip}
}{% else
\setlength{\parindent}{0pt}
\setlength{\parskip}{6pt plus 2pt minus 1pt}
}
\usepackage{hyperref}
\hypersetup{
            pdfborder={0 0 0},
            breaklinks=true}
\urlstyle{same}  % don't use monospace font for urls
\usepackage{listings}
\newcommand{\passthrough}[1]{#1}
\usepackage{longtable,booktabs}
% Fix footnotes in tables (requires footnote package)
\IfFileExists{footnote.sty}{\usepackage{footnote}\makesavenoteenv{longtable}}{}
\usepackage{graphicx,grffile}
\makeatletter
\def\maxwidth{\ifdim\Gin@nat@width>\linewidth\linewidth\else\Gin@nat@width\fi}
\def\maxheight{\ifdim\Gin@nat@height>\textheight\textheight\else\Gin@nat@height\fi}
\makeatother
% Scale images if necessary, so that they will not overflow the page
% margins by default, and it is still possible to overwrite the defaults
% using explicit options in \includegraphics[width, height, ...]{}
\setkeys{Gin}{width=\maxwidth,height=\maxheight,keepaspectratio}
\setlength{\emergencystretch}{3em}  % prevent overfull lines
\providecommand{\tightlist}{%
  \setlength{\itemsep}{0pt}\setlength{\parskip}{0pt}}
\setcounter{secnumdepth}{5}
% Redefines (sub)paragraphs to behave more like sections
\ifx\paragraph\undefined\else
\let\oldparagraph\paragraph
\renewcommand{\paragraph}[1]{\oldparagraph{#1}\mbox{}}
\fi
\ifx\subparagraph\undefined\else
\let\oldsubparagraph\subparagraph
\renewcommand{\subparagraph}[1]{\oldsubparagraph{#1}\mbox{}}
\fi

% set default figure placement to htbp
\makeatletter
\def\fps@figure{htbp}
\makeatother

% Contents of listings-setup.tex
\usepackage{xcolor}
\usepackage{graphicx}
\usepackage{amsmath}
\usepackage{enumitem}

\lstset{
    basicstyle=\footnotesize\ttfamily,
    numbers=right,
    numberstyle=\tiny,
    stepnumber=1,
    numbersep=3pt,
    backgroundcolor=\color{yellow!10},
    showspaces=false,
    showstringspaces=false,
    showtabs=false,
    tabsize=2,
    captionpos=b,
    breaklines=false,
    breakatwhitespace=true,
    breakautoindent=true,
    linewidth=\textwidth
}

\date{}

\begin{document}

\hypertarget{introductie-module-2}{%
\section{Introductie module 2}\label{introductie-module-2}}

Deze week verdiepen we ons in het concept meetonzekerheid. We leren hoe
we \href{/module-2/foutenpropagatiei}{onzekerheden kunnen doorrekenen}
in vergelijkingen. We zien hoe
\href{/module-2/wet-van-grote-aantallen}{onzekerheden veranderen} als we
meer meetpunten aan onze dataset toevoegen. We kijken ook naar relaties
tussen onzekerheden in
\href{/module-2/meerdimensionale-data}{meerdimensionale datasets}, en we
introduceren de \href{/module-2/extra-kansrekenregels}{laatste kans
rekenregels} die vooral voor multidimensionale data belangrijk is.

We werken in de laptopcolleges aan de opdrachten van deze module
\href{/opdrachten-module-2/opdrachten}{M2}. Je vindt in het
\href{/informatie/inleveropdrachten}{schema} wanneer je aan welke
opdrachten werkt en wanneer je deze moet inleveren. Vergeet ook niet te
kijken naar het \href{/tussentoets-ii/inhoud}{oefenmateriaal} voor de
tweede tussentoets. De tweede tussentoets volgt aan het einde van het
derde hoorcollege.

\hypertarget{foutenpropagatie}{%
\chapter{Foutenpropagatie}\label{foutenpropagatie}}

Vaak kunnen we de grootheid die we willen weten niet direct meten, maar
meten we een observabele die zich via een bepaalde functie verhoudt tot
de gezochte grootheid. Of meten we zelfs twee of meer variabelen die we
nodig hebben om de gewilde grootheid te bepalen.

Dit is bijvoorbeeld het geval als we de gemiddelde snelheid van een auto
willen bepalen. Dit zouden we kunnen doen door de tijd te meten die de
auto nodig heeft om een bepaald traject af te leggen. We meten dan de
door de auto gebruikte tijd, \[T\] en de lengte van het traject, \[L\],
en die zetten we dan om in snelheid via de bekende formule \[v=L/T\]. Of
we bepalen bijvoorbeeld de massa van een elementair deeltje (in rust) en
willen dit omzetten naar de energie van het deeltje via de formule
\[E=mc^2\].

Als we de onzekerheid weten op de gemeten grootheden dan kunnen we deze
omzetten naar de grootheid die we eigenlijk willen bepalen. Dit noemen
we het propageren van fouten. In dit hoofdstuk leren we je de
basisregels voor het propageren van \textbf{ongecorreleerde} fouten. Dat
wil zeggen dat als er meerdere onzekerheden worden gepropageerd deze
onzekerheden onafhankelijk zijn; De meting van de ene observabele heeft
geen invloed op de meting van de andere observabele; de fout die we
maken in het meten van de ene grootheid hangt niet af van de fout die we
maken op de andere gemeten grootheid.

Het is goed om alvast te beseffen dat er ook gecorreleerde fouten
bestaan. Er zijn twee oorzaken voor het ontstaan van gecorreleerde
fouten:

\begin{itemize}
\tightlist
\item
  Doordat er in de meting een correlatie is. Een voorbeeld van een
  gecorreleerde fout is als we een oppervlakte van een tafel willen
  weten en we meten de lengte en de breedte met hetzelfde meetlint op.
  Als het meetlint een afwijking heeft waardoor we de lengte te groot
  opmeten, dan zullen we waarschijnlijk ook de breedte te groot opmeten.
\item
  Doordat er een onderliggende parameter is waar beide gemeten
  grootheden vanaf hangen.
\end{itemize}

Hier behandelen we dus alleen ongecorreleerde fouten.

\hypertarget{basisregel}{%
\section{Basisregel}\label{basisregel}}

We beginnen met de \textbf{algemene regel voor het propageren van
ongecorreleerde fouten}. Daarna zullen we laten zien hoe deze regel
eruitziet voor eenvoudige relaties. Deze zou je apart kunnen leren, maar
je kunt ook altijd de basisregel gebruiken. Het resultaat behoort
hetzelfde te zijn. We noteren de onzekerheid op variabele \[x\] in dit
hoofdstuk met \[\Delta x\] waar we eerder ook wel \[\sigma_x\] hebben
gebruikt.

Als \[q = q(x,y,z,\dots)\] een functie is met meerdere ongecorreleerde
variabelen, dan wordt de onzekerheid op \[q\] gegeven door:

\begin{equation}\Delta q = \sqrt{\left(\frac{\delta q}{\delta x}\Delta x  \right)^2+\left(\frac{\delta q}{\delta y}\Delta y\right)^2+\left(\frac{\delta q}{\delta z}\Delta z\right)^2+\dots}\end{equation}

Hierbij zijn \[\frac{\delta q}{\delta x}\],
\[\frac{\delta q}{\delta y}\] etc. de partiÃ«le afgeleiden van \[q\] naar
de betreffende variabele.

We zullen laten zien hoe deze formule werkt aan de hand van een paar
voorbeelden.

\begin{quote}
\textbf{Voorbeeld 1: Factor}

Stel we hebben een vergelijking \[y = c\cdot x\] met een
standaarddeviatie op \[x\] van \[\Delta x\]. Dan is de standaarddeviatie
op \[y\], (\[\Delta y\]), gelijk aan: \newline 
\begin{equation}\displaystyle \Delta y = \sqrt{\left( \frac{\delta y}{\delta x} \Delta x \right)^2} = c \cdot \Delta x.\end{equation}\newline
In dit geval schaalt de onzekerheid op \[x\] (\[\Delta x\]) dus met
dezelfde factor \[c\] tot de onzekerheid op \[y\] (\[\Delta y\]). In het
plaatje hieronder wordt voor een willekeurige waarde \[x_i\] het effect
van de propagatie van \[\Delta x\] rond de waarde \[x_i\] naar de fout
\[\Delta y\] rond \[y_i\] visueel weergegeven. Je kunt duidelijk zien
dat de grootte van \[\Delta y\] veranderd is met de factor
\[c.\]\newline
\end{quote}

\includegraphics{Foutenpropagatie_const.png}\{:width=``40\%''\}

\begin{quote}
\textbf{Voorbeeld 2: Translatie}

Stel we hebben een vergelijking \[y = x + a\] met een standaarddeviatie
op \[x\] van \[\Delta x\]. Dan is de standaarddeviatie op \[y\],
(\[\Delta y\]), gelijk aan: \newline 
\[\displaystyle \Delta y = \sqrt{\left( \frac{\delta y}{\delta x} \Delta x \right)^2} = \Delta x.\]\newline
Wederom geven we het effect van de foutenpropagatie van \[\Delta x\]
rond \[x_i\] naar \[\Delta y\] rond \[y_i\] grafisch weer in het plaatje
hieronder. Je ziet dat de translatie geen effect heeft op de grootte van
de onzekerheid.\newline
\end{quote}

\includegraphics{Foutenpropagatie_trans.png}\{:width=``40\%''\}

\begin{quote}
\textbf{Voorbeeld 3: Macht}

Stel we hebben een vergelijking \[y = x^3\] met een standaarddeviatie op
\[x\] van \[\Delta x\]. Dan is de standaarddeviatie op \[y\],
(\[\Delta y\]), gelijk aan: \newline 
\[\displaystyle \Delta y = \sqrt{\left( \frac{\delta y}{\delta x} \Delta x \right)^2} = 3x^2 \cdot \Delta x.\]\newline
Het effect van de foutenpropagatie volgens deze formule van \[\Delta x\]
rond \[x_i\] naar \[\Delta y\] rond \[y_i\] wordt weer grafisch
weergegeven in het plaatje hieronder. Je kunt zien dat de mate waarin de
grootte van \[\Delta x\] verandert afhangt van de gekozen waarde van
\[x_i\], op sommige plekken is hij kleiner geworden, op andere plekke
groter. \newline
\end{quote}

\includegraphics{Foutenpropagatie_cube.png}\{:width=``40\%''\}

\begin{quote}
\textbf{Voorbeeld 4}

Stel we hebben een vergelijking \[y = ax + bx^2 + c\] met een
standaarddeviatie op \[x\] van \[\Delta x\]. Dan is de standaarddeviatie
op \[y\], (\[\Delta y\]), gelijk aan: \newline 
\[\displaystyle \Delta y = \sqrt{\left( \frac{\delta y}{\delta x} \Delta x \right)^2} = (a + 2bx) \Delta x.\]\newline
In het plaatje hieronder geven we nu voor verschillende waardes \[x_i\]
de foutenpropagatie van \[\Delta x\] naar \[\Delta y\] de grafische
interpretatie. We zien dat het niet alleen de relatieve grootte van
\[\Delta y\] afhangt van de gekozen waarde van \[x_i\] maar dat op
sommige plaatsen de boven en ondergrens van de onzekerheid zijn
geÃ¯nverteerd.\newline
\end{quote}

\includegraphics{Foutenpropagatie_func.png}\{:width=``40\%''\}

\begin{quote}
\textbf{Voorbeeld 5}

Stel we hebben een vergelijking \[z = ax + y^2\] met standaarddeviaties
\[\Delta x\] en \[\Delta y\] . Dan is de standaarddeviatie op \[z\],
(\[\Delta z\]), gelijk aan: \newline 
\[\displaystyle \Delta z = \sqrt{ \left( \frac{\delta z}{\delta x} \Delta x \right)^2 + \left( \frac{\delta z}{\delta y} \Delta y \right)^2} = \sqrt{(a \Delta x)^2 + (2y \Delta y)^2}.\]

\textbf{Voorbeeld 6}

Stel we hebben een vergelijking \[z = ax + y^2 + 2xy\] met
standaarddeviaties \[\Delta x\] en \[\Delta y\] . Dan is de
standaarddeviatie op \[z\], (\[\Delta z\]), gelijk aan: \newline 
\[\displaystyle \Delta z = \sqrt{ \left( \frac{\delta z}{\delta x} \Delta x \right)^2 + \left( \frac{\delta z}{\delta y} \Delta y \right)^2} = \sqrt{\left( (a + 2y) \cdot \Delta x \right)^2 + \left( (2y + 2x)\cdot  \Delta y \right)^2}.\]
\end{quote}

\hypertarget{som-en-verschil}{%
\section{Som en verschil}\label{som-en-verschil}}

De algemene regel kan eenvoudig worden uitgeschreven naar de regel voor
som en verschil.\\
Als \[q = x + y\] of \[q = x - y \] dan wordt de onzekerheid op \[q\]
gegeven door:

\begin{equation}\displaystyle \Delta q = \sqrt{\left(\frac{\delta q}{\delta x} \Delta x \right)^2 + \left( \frac{\delta q}{\delta y} \Delta y \right)^2} = \sqrt{\left(\Delta x\right)^2+\left(\Delta y\right)^2}.\end{equation}

We mogen de varianties \[(\Delta x)^2 \] en \[(\Delta y)^2\] in het
geval van een vergelijking met enkel sommen en/of verschillen dus
optellen.

\hypertarget{vermenigvuldigen-met-constante}{%
\section{Vermenigvuldigen met
constante}\label{vermenigvuldigen-met-constante}}

Als \[q\] een exacte veelvoud \[c\] is van de gemeten waarde \[x\], dus
\[q = c \cdot x\], dan geldt:\newline

\begin{equation}\displaystyle \Delta q = \sqrt{\left( \frac{\delta q}{\delta x} \Delta x \right) ^2} = |c| \Delta x.\end{equation}

De onzekerheid op \[q\] is dus gelijk aan de onzekerheid op \[x\]
geschaald met dezelfde factor \[c.\]

\hypertarget{vermenigvuldigen-met-variabelen}{%
\section{Vermenigvuldigen met
variabelen}\label{vermenigvuldigen-met-variabelen}}

Als \[q\] een vermenigvuldiging is van meerdere variabelen, dus
bijvoorbeeld \[q = x\cdot y \cdot z\] dan geldt:

\begin{equation}\displaystyle \Delta q = \sqrt{\left( \frac{\delta q}{\delta x} \Delta x \right)^2 +\left( \frac{\delta q}{\delta y} \Delta y \right)^2 +\left( \frac{\delta q}{\delta z} \Delta z \right)^2} = \sqrt{\left( \frac{q}{x} \Delta x\right)^2 + \left( \frac{q}{y} \Delta y\right)^2 +\left( \frac{q}{z} \Delta z \right)^2 }.\end{equation}

Dit kan je eenvoudiger schrijven als: \newline

\begin{equation}\displaystyle \frac{\Delta q}{q} = \sqrt{\left( \frac{\Delta x}{x} \right)^2 + \left(\frac{\Delta z}{z}\right)^2 + \left(\frac{\Delta z}{z} \right)^2}.\end{equation}

Ofwel de relatieve fout \[\frac{\Delta q}{q}\] is gelijk aan de
kwadratische som van de variabelen.

\begin{quote}
\textbf{Voorbeeld - foutenpropagatie en afronding van de getallen}

Stel dat we de lengte van het blokje hebben gemeten en we lezen de
volgende waarde af:

\begin{itemize}
\tightlist
\item
  De \[\text{lengte (l)} = 7.60 \pm 0.10 \text{ cm}\]
\item
  De \[\text{breedte (b)} = 4.10 \pm 0.20 \text{ cm}\]
\item
  De \[\text{hoogte (h)} = 2.00 \pm 0.20 \text{ cm}\]
\end{itemize}

Het volume van het blokje wordt gegeven door:

\[V = l\cdot b\cdot h = 7.60 \cdot 4.10 \cdot 2.00 = 62.32 \text{ cm}^3\]

We gebruiken de regel dat als \[q = x\cdot y\cdot \dots\] dan:

\[\frac{\Delta q}{|q|} = \sqrt{\left(\frac{\Delta x}{x}\right)^2 \left(\frac{\Delta y}{y}\right)^2+\left(\frac{\Delta z}{z}\right)^2} \]

Dus:

\[\begin{aligned}\frac{\Delta V}{|V|} &= \sqrt{\left(\frac{\Delta l}{l}\right)^2+\left(\frac{\Delta b}{b}\right)^2+\left(\frac{\Delta h}{h}\right)^2} \\ &= \sqrt{\left(\frac{0.1}{7.6}\right)^2+\left(\frac{0.2}{4.1}\right)^2+\left(\frac{0.2}{2.0}\right)^2}\\ &= 0.01255 \dots \end{aligned}\]

We ronden dit nog niet af, dat doen we pas als we de absolute fout
hebben:

\[\begin{aligned} \Delta V &= \frac{\Delta V}{|V|} \cdot |V| \\ &= 0.01255\dots \cdot 62.32 \\ &= 0.78228 \dots \\ &\approx 0.78\end{aligned}\]

Het gemeten volume van het blokje is dus
\[V = 62.32 \pm 0.78 \text{ cm}^3\]
\end{quote}

\hypertarget{wet-van-grote-aantallen}{%
\chapter{Wet van Grote Aantallen}\label{wet-van-grote-aantallen}}

In opgave M1.4 hebben we gezien hoe de spreiding van een gemeten
gemiddelde van metingen steeds kleiner wordt als we meer data gebruiken
om het gemiddelde te bepalen. Dit is een belangrijke observatie. Het
geeft aan dat hoe meer data we hebben, hoe nauwkeuriger we ons resultaat
weten. Je voelt misschien al aan dat dit niet altijd op gaat. Wanneer
dit wel en wanneer dit niet opgaat zullen we hier bespreken.

We bespreken hier twee regels, of wetten, de \[\sqrt{n}\]-wet en de wet
van grote aantallen. De eerste wet zegt dat we een gemiddelde, onder
bepaalde voorwaarden, steeds beter kennen als we meer datapunten
meenemen. De tweede wet zegt dat het gemiddelde van de steekproef
langzaam zal convergeren naar het gemiddelde van de populatie.

\hypertarget{de-sqrtn-wet}{%
\section{\texorpdfstring{De
\[\sqrt{n}\]-wet}{De \textbackslash{}sqrt\{n\}-wet}}\label{de-sqrtn-wet}}

We kijken naar twee onafhankelijke stochasten, \[X\] en \[Y\]. De
verwachtingswaarde van \[X+Y\] is gelijk aan:

\begin{equation}\displaystyle{ E(X+Y)= E(X)+E(Y) }\end{equation}

Als \[X\] en \[Y\] onafhankelijk zijn dan geldt ook:

\begin{equation}\displaystyle{Var(X+Y)= Var(X)+Var(Y)}\end{equation}

Het ziet er misschien ingewikkeld uit, maar het enige wat we doen is een
nieuwe variabele definiÃ«ren die de som is van twee variabelen. De
variantie op de som vinden we via de gewone fouten propagatie
\href{/module-2/foutenpropagatiei}{regels}.

Stel nu dat we dit uitbreiden. En we nemen de som van \[N\]
onafhankelijk stochasten, \[X_1,X_2,...,X_N\] die elk dezelfde
onderliggende verdeling kennen. Dat wil zeggen dat ze allemaal dezelfde
verwachtingswaarde en dezelfde variantie hebben.

NB. De verwachtingswaarde is niet gelijk aan de gemeten waarde. Kijk
voor dit verschil nog eens naar
\href{/module-1/basisbegrippen}{basisbegrippen} in module 1. Als je
terugdenkt aan de opgave van de kogels is de verwachtingswaarde van de
massa van een kogel gelijk aan de gemiddelde massa van alle kogels. Als
we een willekeurige kogel uit de ton pakken, dan is de gemiddelde massa
van de kogels in de ton, de \emph{verwachting} die we hebben van de
massa van de kogel die we pakken. De verwachtingswaarde is dus hier het
gemiddelde.

De variantie is de spreiding op de massa distributie. Als je een
willekeurige kogel uit de ton pakt is de kans heel klein dat de massa
precies gelijk is aan de verwachtingswaarde van de massa. De variantie
geeft aan in welk gebied van waardes we verwachten de massa van de kogel
te vinden.

De formule voor de som kunnen we nu schrijven als:

\begin{equation}\displaystyle{ Som_N = X_1 + X_2 + ... + X_N.}\end{equation}

En het gemiddelde kunnen we schrijven als:

\begin{equation}\displaystyle { E(<{X_1 ... X_N}>) = \frac{Som_n}{N}.}\end{equation}

Als de verwachtingswaarde van een enkele stochast \[E(X_i)\] gelijk is
aan het gemiddelde \[\mu\] en de variantie gelijk is aan
\[Var(X_i) = \sigma^2\], dan geldt nu voor de verwachtingswaarde van de
som:

\begin{equation}\displaystyle{ E(S_N)= \mu N} \end{equation}

en voor het gemiddelde:

\begin{equation}\displaystyle{E(<{X_1 ... X_N}>) = \mu.}\end{equation}

En dan geldt voor de variantie

\begin{equation}\displaystyle{ Var(S_N) = N \sigma^2 } \end{equation}

en

\begin{equation}\displaystyle{ Var(<{X_1 ... X_N}>) = \frac{\sigma^2}{N}.}\end{equation}

Dit betekent dat \textbf{de standaarddeviatie van de som van de
stochasten} gelijk is aan \[\sigma \cdot \sqrt{N}\].\\
De standaarddeviatie van het gemiddelde is dan gelijk aan:

\begin{equation}\displaystyle{\text{standaarddeviatie op het gemiddelde is: }\frac{\sigma \cdot \sqrt{N}}{N} = \frac{\sigma}{\sqrt{N}}}.\end{equation}

Dit betekent dus dat als we het gemiddelde van de massa van N aantal
kogels nemen waarbij de kogels een Normale distributie hebben met een
gemiddelde \[\mu\] en een standaarddeviatie van \[\sigma\], de
onzekerheid op de bepaalde gemiddelde massa gelijk is aan
\[\sigma/\sqrt{N}\].\\
Hoe meer kogels we wegen en meenemen in ons gemiddelde, hoe nauwkeuriger
we dit gemiddelde kennen.

\hypertarget{de-wet-van-grote-aantallen}{%
\section{De wet van Grote Aantallen}\label{de-wet-van-grote-aantallen}}

IntuÃ¯tief voelen we aan dat hoe meer metingen we doen, hoe meer
informatie we hebben, en hoe nauwkeuriger ons resultaat is.

De \textbf{wet van grote aantallen} zegt dat het berekende steekproef
gemiddelde, \[<{X}>\], van een distributie met een eindige variantie,
convergeert naar het populatie gemiddelde \[\mu\] voor steeds grote
steekproeven:\newline

\[{\displaystyle lim_{N \to \infty} P( | \lt X \gt - \mu| \gt \epsilon) = 0 } \]

Ofwel de kans dat het steekproef gemiddelde meer afwijkt van het
populatie gemiddelde dan een heel klein getal convergeert naar 0 voor
oneindig grote steekproeven. Voor eindige populaties is dit natuurlijk
zeker waar. Maar denk hier ook aan oneindig grote, of nagenoeg oneindig
grote populaties, zoals bijvoorbeeld als je de gemiddelde massa van het
electron wilt bepalen.

\textbf{Tip:} In deze
\href{https://www.youtube.com/watch?v=MntX3zWNWec}{video} wordt de wet
van grote aantallen nogmaals duidelijk uitgelegd.

Als je de wet goed leest zie je dat er een voorwaarde aan vast zit.
Namelijk dat de variantie van de stochast eindig moet zijn, en dat dus
de verwachtingswaarde van de stochast bepaald is. Er bestaan
distributies, zoals de
\href{https://nl.wikipedia.org/wiki/Cauchy-verdeling}{Cauchy} of de
\href{https://en.wikipedia.org/wiki/Landau_distribution}{Landau}
distributie waarvoor dit dus niet geldt. Deze distributies hebben
oneindig lange staarten. Hieronder zie je hoe de Cauchy distributie
eruit ziet.

\includegraphics{CauchyDistributie.png}\{:width=``80\%''\}

Wiskundig kan de wet van de grote aantallen dus weleens voor problemen
zorgen. In Natuurkundige experimenten zijn verdelingen uiteindelijk vaak
beknot door bijvoorbeeld de eindigheid van energie. Voor Natuurkundige
experimenten gaat de wet van grote aantallen dus vaak wel op.

Overigens noemen we deze wet van grote aantallen de \emph{zwakke} wet
van grote aantallen, er bestaat ook een \emph{sterke} wet. We gaan hier
niet in op de kleine verschillen tussen deze twee wetten, online kun je
er eventueel genoeg over vinden.

\hypertarget{meerdimensionale-datasets}{%
\chapter{Meerdimensionale datasets}\label{meerdimensionale-datasets}}

Het komt vaak voor dat we datasets hebben waarbij we meerdere variabelen
tegelijkertijd hebben gemeten. Bijvoorbeeld als we een steekproef doen
onder de bevolking waarbij we allerlei gegevens tegelijkertijd opvragen
zoals leeftijd, inkomen, gezinssamenstelling etc. We kunnen dan niet
alleen naar verdelingen kijken van bijvoorbeeld alleen het inkomen, maar
we kunnen ook naar het inkomen kijken \emph{afhankelijk} van de
leeftijd. Dit levert dus meer informatie op dan dat we deze gegevens
afzonderlijk zouden hebben verzameld. Ook in natuurkundige experimenten
komen multidimensionale datasets veel voor.

Voor elke afzonderlijke variabele kunnen we bijvoorbeeld het gemiddelde
en de standaarddeviatie berekenen met behulp van de formules die we in
\href{/module-1/basisbegrippen}{`Basisbegrippen'} hebben geÃ¯ntroduceerd.
Maar we kunnen nu ook kijken of de waarde van een observabele afhangt
van een andere observabele in de dataset. Dit noemen we correlatie. Ook
kunnen we berekenen of een spreiding in een variabele afhangt van de
waarde van een andere variabele. We noemen die covariantie. Hieronder
introduceren we eerst covariantie, daaronder komt correlatie aan bod.

\hypertarget{variantie-en-covariantie}{%
\section{Variantie en covariantie}\label{variantie-en-covariantie}}

De variantie geeft zoals eerder besproken (onder
\href{/module-1/basisbegrippen}{`Basisbegrippen'}) een maat voor de
spreiding van een dataset aan. Bij een 2D dataset waarbij een variabele
wordt aangegeven op de \[x\]-as en een andere variabelen op de \[y\]-as
wordt de mate van spreiding o.a. aangegeven met de \emph{covariantie}.

De covariantie bij een 2D dataset geeft aan in welke mate de data
verspreid is over het twee dimensionale vlak.

Voor twee variabelen \[x\] en \[y\] wordt de covariantie aangeduid met
\[cov(x,y)\] en gegeven door:

\begin{equation}cov(x,y) = E((x-E_x)(y-E_y))\end{equation}

Hier staat \[E\] voor de \emph{verwachtingswaarde}. De
verwachtingswaarde voor \begin{equation}x\end{equation} en \[y\] worden
respectievelijk aangegeven met \[E_x\] en \[E_y\]. De formule geeft dus
aan dat de covariantie gelijk is aan de verwachtingswaarde van het
verschil tussen de waarde van de variabele \[x\] en de
verwachtingswaarde van \[x\] vermenigvuldigd met het verschil tussen de
variabele \[y\] en de verwachtingswaarde van \[y\].

Als voor waardes \[x\] die bovengemiddeld zijn, overwegend samen gaan
met relatief hoge waardes van \[y\], dan hebben we te maken met een
positieve waarde voor de covariantie. Als bij de waarden voor relatief
hoge waardes van \[x\] de waardes van \[y\] voornamelijk onder de
verwachtingswaarde liggen, dan is de covariantie negatief. Als de
covariantie gelijk is aan nul dan is er, gemiddeld over de hele dataset,
geen afhankelijkheid. Het kan zijn dat voor delen van de dataset wel
degelijk een positieve covariantie bestaat, deze wordt dan opgeheven
door een ander gedeelte met een negatieve covariantie.

Met de volgende formules kun je de covariantie van een dataset
uitrekenen:

\begin{itemize}
\item
  Voor discrete verdelingen geldt :
  \begin{equation}{\displaystyle cov(x,y) = \frac{1}{n}\sum^n_i (x_i-<{x}>)\cdot (y_i-<{y}>)}.\end{equation}
\item
  Voor continue verdelingen geldt:
  \begin{equation}{\displaystyle cov(x,y) = \int_{-\infty}^{\infty}\int_{-\infty}^{\infty}xy \cdot f(x,y) dy dx }\end{equation}
\end{itemize}

De covariantie geeft dus aan in hoeverre waarden van de ene variabele
toenemen/afnemen bij toenemende waarden van de andere variabele. De
covariantie is een heel nuttige maat maar lastig te interpreteren
vanwege de dimensies die, net als bij de variantie, niet dezelfde zijn
als de variabelen zelf. Eenvoudiger is om naar de correlatiecoÃ«fficiÃ«nt
\[\rho\] te kijken.

Hierkun je een filmpje zien die covariantie uitlegt.

\hypertarget{correlatie}{%
\section{Correlatie}\label{correlatie}}

De correlatiecoÃ«fficiÃ«nt \[\rho\] is gedefinieerd als:

\begin{equation}\rho_{x,y} = \frac{cov(x,y)}{\sigma_x \sigma_y}\end{equation}

Hierbij is \[cov(x,y)\] de covariantie tussen variabele \[x\] en
variabele \[y\], en zijn \[\sigma_x\] en \[\sigma_y\] de
standaardafwijkingen van variabele \[x\] en \[y\] respectievelijk. Deze
reken je dus uit met de formule die hierboven is gedefinieerd.

Als er geen correlatie is tussen de twee variabelen, dan is
correlatiecoÃ«fficiÃ«nt gelijk aan nul. Is de correlatiecoÃ«fficiÃ«nt tussen
de twee variabelen gelijk aan \[1\] of aan \[-1\] dan zijn de twee
variabelen maximaal afhankelijk. In het geval van een
correlatiecoÃ«fficiÃ«nt gelijk aan \[1\] is dit een positief lineair
verband, in het geval van een correlatiecoÃ«fficiÃ«nt gelijk aan \[-1\] is
dit een lineair verband met negatieve helling.

Hieronder zijn een aantal 2D datasets weergegeven met verschillende
correlatiecoÃ«fficiÃ«nten:

Dataset met een correlatiecoÃ«fficiÃ«nt \[\rho_{x,y} = 0 \]:

\includegraphics{Plot1_Correlatie_0.png}\{:width=``60\%''\}

Dataset met een correlatiecoÃ«fficiÃ«nt \[\rho_{x,y} = 1 \]:

\includegraphics{Plot1_Correlatie1.png}\{:width=``60\%''\}

Dataset met een correlatiecoÃ«fficiÃ«nt \[\rho_{x,y} = -1 \]:

\includegraphics{Plot1_Correlatie_min1.png}\{:width=``60\%''\}

Datasets met een correlatiecoÃ«fficiÃ«nt \[\rho_{x,y} = -0.8\] en
\[\rho_{x,y} = 0.8\]:

\includegraphics{Plot1_Correlatie_min0punt8.png}\{:width=``45\%''\}\includegraphics{Plot1_Correlatie_0punt8.png}\{:width=``45\%''\}

Datasets met een correlatiecoÃ«fficiÃ«nt \[\rho_{x,y} = -0.3\] en
\[\rho_{x,y} = 0.3\]:

\includegraphics{Plot1_Correlatie_min0punt3.png}\{:width=``45\%''\}\includegraphics{Plot1_Correlatie_0punt3.png}\{:width=``45\%''\}

Hoe dichter de correlatiecoÃ«fficiÃ«nt bij een waarde van \[1\] of \[-1\]
zit des te groter is de afhankelijkheid van de variabelen. Hoe te
dichter de correlatiecoÃ«fficiÃ«nt bij nul zit des te kleiner is de
correlatie tussen de variabelen.

Je kunt hiereen filmpje vinden waarin correlatie ook wordt uitgelegd. Er
zijn meerdere `spelletjes' op internet waarbij je kunt oefenen met het
herkennen en raden van de correlatiecoÃ«fficiÃ«nt van twee variabelen.
Kijk bijvoorbeeld eens bij
\href{https://www.geogebra.org/m/KE6JfuF9}{Geogebra-Correlatie game} of
\href{http://guessthecorrelation.com/}{Guess the correlation}.

\hypertarget{correlatie-en-causaliteit}{%
\section{Correlatie en causaliteit}\label{correlatie-en-causaliteit}}

Soms betekent correlatie dat er oorzakelijk verband is tussen de twee
observabelen. Dat wil zeggen dat de ene observabele invloed heeft op de
andere observabele.

Een voorbeeld hiervan is bijvoorbeeld als je kijkt naar de ijsverkoop en
de buitentemperatuur. Omdat het warm is buiten hebben mensen meer trek
in een ijsje. Het is dus niet zo gek dat je er een verband tussen vindt.
Dit verband noemen we een \textbf{causaal} verband. Iets wordt
veroorzaakt door iets anders.

In wetenschappelijk onderzoek zijn we altijd op zoek naar correlaties.
Immers, die kunnen wijzen op onbekende wetten of onderliggende, nog
onbekende fenomenen. Toch moet je behoorlijk oppassen om meteen een
conclusie te trekken. Niet alle observabelen die een gecorreleerd zijn
hebben een causaal verband. Het kan ook toeval zijn, als je maar genoeg
variabelen tegen elkaar uitzet zal je er altijd wat vinden die toevallig
een correlatie vertonen. Het kan ook komen door een verborgen parameter.
Dit wordt ook wel Simpsons paradox genoemd.

Een bekend voorbeeld van een Simpsons paradox is een onderzoek naar
veiligheid op de scheepvaart. Er is gebleken dat er een positieve
correlatie is tussen het dragen van reddingsvesten en het aantal
ongevallen waarbij mensen verdronken zijn. Dit is natuurlijk niet wat je
verwacht! Voordat je adviseert om alle reddingsvesten weg te laten
gooien is het goed om nog iets verder onderzoek te plegen. Wat blijkt,
de reddingsvesten worden alleen aangetrokken bij slecht weer op zee. De
verborgen parameter is dus het weer. Als we de data nog een keer goed
bekijken en nu kijken naar alleen de categorie slecht weer dan zien we
dat de overlevingskans juist vele malen hoger als een reddingsvest wordt
gedragen.

De les die je hieruit moet leren is dat je altijd heel goed moet
nadenken over wat een verborgen parameter zou kunnen zijn en niet zomaar
de conclusie trekken dat een correlatie ook causaliteit impliceert. Het
is goed om zo'n conclusie eerst te onderbouwen met een plausibele
verklaring.

\hypertarget{extra-kans-rekenregels}{%
\chapter{Extra kans rekenregels}\label{extra-kans-rekenregels}}

In \href{/module-1/kanstheorie}{module 1} hebben we de complement, de
en-regel en de of-regel geleerd voor het rekenen met kansen. Aan deze
regels waren enkele voorwaarden verbonden.

De of-regel geldt alleen als de metingen A en B wederzijds uitsluitend
zijn. Dat betekent dat een meting A niet kan voorkomen als B gemeten is.

\begin{quote}
Een voorbeeld van kansen die niet wederzijds uitsluitend zijn is, als we
weer kijken naar een set kaarten waar A bijvoorbeeld de kleur rood is en
B het getal 4. Er bestaan rode kaarten met getal vier en in dit geval
mogen we de kansen dus niet optellen. \newline

\[P(\text{rood of 4}) \neq P(\text{rood}) + P(4)\]
\end{quote}

We breiden de regels hier verder uit en gaan kijken naar het combineren
van kansen die niet wederzijds uitsluitend zijn. We kijken ook naar het
begrip conditionele kans en introduceren Bayes theorema die gebruikt kan
worden om informatie van kansen om te rekenen.

\hypertarget{de-of-regel-wanneer-a-en-b-niet-wederzijds-uitsluitend-zijn}{%
\subsection{De of regel wanneer A en B niet wederzijds uitsluitend
zijn:}\label{de-of-regel-wanneer-a-en-b-niet-wederzijds-uitsluitend-zijn}}

In het geval A en B niet wederzijds uitsluitend zijn dan:\newline

\[P(\text{A en B}) \equiv P(A \cap B) >0.\]

\newline

De kans dat A of B gemeten wordt is dan:

\[P(\text{A of B}) = P(A) + P(B) - P(\text{A en B}).\]

\begin{quote}
Voorbeeld: De kans dat een kaart rood is en een vier heeft is 2/52. De
kans dat een kaart rood is of een vier is nu gelijk aan P(1/2) + P(4/52)
- P(2/52) = 28/52.
\end{quote}

De term \[(\text{A en B})\] noemen we ook wel de doorsnede, of
intersectie, van A en B. Het is het overlappende deel van elementen in
de verzameling. Hieronder zie je het uitgebeeld in een Venn diagram. De
doorsnede wordt ook wel genoteerd met \[A \cap B\]. \newline
\includegraphics{180px-Venn0001.svg.png}\{:width=``60\%''\}
\emph{``doorsnede van A en B (bron wikipedia)''}

De vereniging van \[A\] en \[B\] wordt genoteerd met \[A \cup B\] en is
de verzameling van alle elementen van A en B. Hieronder het Venn diagram
voor de verzameling.\newline
\includegraphics{180px-Venn0111.svg.png}\{:width=``60\%''\}
\emph{``vereniging van A en B (bron wikipedia)''}

En zo kun je ook het complement van A laten zien: \newline
\includegraphics{180px-Venn1010.svg.png}\{:width=``60\%''\}
\emph{``complement van A (bron wikipedia)''}

\hypertarget{conditionele-kans}{%
\subsection{Conditionele kans}\label{conditionele-kans}}

Een conditionele kans wordt geschreven als \[P(A|B)\] en kun je lezen
als ``Wat is de kans op meting A gegeven dat B is gemeten.''. Let op dat
\[P(A|B)\neq P(B|A)\]! Een sprekend voorbeeld hiervan is de volgende. De
kans dat een persoon zwanger is gegeven dat de persoon een vrouw is,
\[P(\text{zwanger}|\text{vrouw})\], is niet gelijk aan de kans dat
iemand een vrouw is gegeven dat de persoon zwanger is,
\[P(\text{vrouw}|\text{zwanger})\]. De laatste kans is duidelijk gelijk
aan 1, als je zwanger bent ben je zeker een vrouw. De eerste kans is een
stuk kleiner!

De conditionele kans kunnen we berekenen met: \newline

\[\displaystyle{P(A|B) = \frac{P(A \cap B)}{P(B)}}.\]

\newline

De noemer in deze vergelijking, \[P(B)\], noemen we ook wel een
normalisatie term. De kans \[P(A \cap B)\] moet genormaliseerd worden
naar de kans \[P(B)\], immers het is al een gegeven dat \[B\] waar is.

Visueel is dit wellicht het meest eenvoudige om te zien. Als het gegeven
is dat de uitkomst in het deelgebied B ligt, dan is de kans dat het ook
de waarde A bezit gelijk aan het oppervlak van de overlap tussen A en B
gedeeld door het oppervlak van B. Immers dat het B is weten we al, dus
we moeten alle kansen normaliseren naar B.

\hypertarget{bayes-theorema}{%
\subsection{Bayes theorema}\label{bayes-theorema}}

Met behulp van de conditionele kans formule kunnen we nu Bayes theorema
afleiden. \newline Het combineren van de formules van \[P(A|B)\] en
\[P(B|A)\]:

\[P(A \cap B) \equiv P(B \cap A) =  P(B|A) \cdot P(A) = P(A|B) \cdot P(B)\]

geeft:

\[\displaystyle P(A|B) = \frac{P(B|A) \cdot P(A)}{P(B)}\]

\newline

Dit theorema maakt het mogelijk om nieuwe informatie toe te voegen aan
de kennis van de kans. In \href{/module-1/kanstheorie}{module 1} hebben
we het kort over Bayesiaanse kans definitie gehad. Dit theorema staat
centraal in Bayesiaanse kans. Het is wel belangrijk om te weten dat deze
wiskundige vergelijking ook opgaat in de Frequentist benadering van
kans.

Bekijk ook even het kennisclipje over Extra Kansrekenregels op Canvas!

\hypertarget{opdrachten-module-2}{%
\chapter{Opdrachten module 2}\label{opdrachten-module-2}}

Tijdens laptopcolleges 3 en 4 werken we aan het de opdrachten van module
2. In deze module gaan we werken aan de volgende opdrachten.

\begin{itemize}
\tightlist
\item
  \href{/opdrachten-module-2/groteaantallen}{M2.1 Grote Aantallen II **}
\item
  \href{/opdrachten-module-2/meesjes}{M2.2 Meesjes ****}
\item
  \href{/opdrachten-module-2/halfwaardedikteii}{M2.3 Halfwaardedikte II
  ***}
\end{itemize}

De sterren geven een indicatie voor hoeveel werk een opdracht is. Let op
dat je deze week goed plant!

De antwoorden van de opdrachten moet je invoeren in
\href{InlevertemplateModule2.docx}{dit template} en als \textbf{pdf}
bestand inleveren samen met de code voor de 3 opdrachten via ANS. De
deadlines voor de inleveropdrachten en informatie over ANS kun je
\href{/informatie/inleveropdrachten}{hier} vinden.

Als je vragen hebt, stel deze dan aan de assistent of stuur een email
naar de coÃ¶rdinator.

Vergeet niet om ook even te kijken naar de
\href{/tussentoets-ii/oefenopgaves}{oefen opgaves} ter voorbereiding van
de tweede tussentoets die aan het einde van het derde hoorcollege plaats
vindt.

Veel succes!

\hypertarget{opdracht-m2.1-grote-aantallen-ii}{%
\section{Opdracht M2.1 Grote Aantallen II
**}\label{opdracht-m2.1-grote-aantallen-ii}}

We gaan verder kijken naar de ton met kogels uit opgave M1.4. In dit
opgave begonnen we met een ton met 80 kogels en berekenden we het
gemiddelde, \[g_n = \bar{m_n}\] over de eerste \[n\] kogels van de set.
Zo kregen we de distributie van \[g_n\] versus \[n\], net als in opgave
M1.4.\\
Voordat je verder gaat, controleer eerst even in ANS of je dit goed hebt
gedaan en corrigeer eventueel je fouten.

We gaan nu naar meerdere tonnen kijken, steeds met 80 kogels en uit
dezelfde fabriek. We gaan steeds de waardes van \[g_n\] opnieuw
berekenen, voor elke ton weer. Als we alle gemiddelde waardes \[g_n\]
van Ã©Ã©n ton hebben berekend, dan beginnen we weer opnieuw met een nieuwe
ton met 80 kogels. Dit herhalen we 100 keer.\\
We gaan er in deze opgave stap voor stap doorheen.

\begin{quote}
Maak eerst 100 verschillende datasets. Elke dataset is een ton met 80
kogels. Dit kan je doen door steeds een andere seed mee te geven aan de
datasetgenerator:

\begin{lstlisting}
  datasets = [ds.DataSetGroteAantallen(i) for i in range(0,100)]
\end{lstlisting}
\end{quote}

Je hebt nu een \textbf{\passthrough{\lstinline!list!}} die
\textbf{\passthrough{\lstinline!datasets!}} heet met 100 items. Elke
item is een dataset met elk 80 meetwaardes.

\begin{quote}
\begin{itemize}
\item
  \textbf{M2.1a) Maak nu eerst een histogram van \emph{alle eerste}
  elementen, \[m_1\], van de 100 datasets. Zorg dat je histogram er
  netjes uitziet.} \newline\newline
\item
  \textbf{M2.1b) Wat is het gemiddelde, \[g_1\], en de standaarddeviatie
  \[s_1\] van dit histogram? Denk bij het noteren aan de eenheden en de
  juiste notatie!}
\end{itemize}
\end{quote}

We gaan nu experimenten vergelijken waarin we steeds het gemiddelde over
de eerste 10 metingen \[(g_{10})\] hebben berekend.

\begin{quote}
\begin{itemize}
\item
  \textbf{M2.1c) Bereken voor elk van de 100 datasets het gemiddelde
  over de eerste 10 metingen en laat de distributie van deze gemiddeldes
  \[g_{10}\] zien in een histogram.} \newline\newline
\item
  \textbf{M2.1d) Bereken van deze distributie het gemiddelde\\
  \[\bar{g_{10}}\], dit is het gemiddelde van de gemiddeldes \[g_{10}\].
  Bereken ook de standaarddeviatie van de gemiddeldes \[s_{g_{10}}\] (de
  standaarddeviatie van de gemiddeldes \[g_{10}\]).}
\end{itemize}
\end{quote}

We gaan dit nu herhalen voor met verschillende groottes van de
steekproef \[n\]. Maak een functie die de standaarddeviatie \[s_{g_n}\]
van de 100 berekende gemiddeldes \[g_n\] die berekend zijn over de
eerste \[n\] punten terug geeft.

Roep nu de functie aan voor de volgende waardes van \[n\]: 1, 5, 10, 20,
30, 40, 50, 60, 70, 80. Controleer of de punten voor \[n=1\] en \[n=10\]
dezelfde resultaten opleveren als dat je net had.

\begin{quote}
\begin{itemize}
\item
  \textbf{M2.1e) Maak nu een grafiek waarin je de berekende
  standaarddeviaties \[s_{g_n}\] uitzet tegen de grootte van de
  steekproeven, \[n\].} \newline\newline
\item
  \textbf{M2.1f) Maak een nieuwe grafiek waarin je de berekende
  \[s_{g_n}\] uitzet tegen \[1/\sqrt{n}\].}\newline\newline
\item
  \textbf{M2.1g) Kun je iets zeggen over de grafieken? Beschrijf wat je
  ziet en probeer daar een conclusie uit te trekken.}
\end{itemize}
\end{quote}

Wat we hebben gedaan in deze opdracht is illustreren wat er gebeurd als
we een steeds grotere steekproef nemen.

\hypertarget{m2.2-meesjes}{%
\section{M2.2 Meesjes ****}\label{m2.2-meesjes}}

Je vindt helaas een dood meesje in de tuin. Het lijkt op een koolmeesje
maar het zou ook een pimpelmeesje kunnen zijn. Deze twee vogeltjes
lijken erg veel op elkaar. Er zijn manierenom pimpelmeesjes van
koolmeesjes te onderscheiden met behulp van uiterlijke kenmerken. Maar
je bent een Natuurkundige en geen Bioloog. Online vind je een dataset
met informatie over het massa en de spanwijdte van beide soorten
meesjes.

Voordat we aan deze opdracht beginnen moeten we eerst een nieuwe versie
downloaden van de
\href{https://das.mprog.nl/course/12\%20Opdrachten\%20Module\%201/00\%20Opdrachten/DAS_DatasetGenerator.py}{\textbf{\passthrough{\lstinline!DAS\_DatasetGenerator.py!}}}.
Zonder de nieuwe versie werkt deze opgave niet. Download ook het bestand
\href{M2.2_Meesjes.py}{\textbf{\passthrough{\lstinline!M2.2\_Meesjes.py!}}}
en zorg dat deze in dezelfde folder staat als het
\passthrough{\lstinline!DAS\_DatasetGenerator.py!} bestand.

We genereren eerst een twee datasets met behulp van de volgende regel
code:

\begin{lstlisting}
m_km, span_km, m_pm, span_pm = ds.datasetVogeltjes()
\end{lstlisting}

De variabelen hebben de volgende betekenis:

\begin{lstlisting}
m_km    : de massa van een koolmeesje in gram
span_km : de spanwijdte van een koolmeesje in cm
\end{lstlisting}

De laatste twee variabelen zijn de datapunten voor pimpelmeesjes. De
twee variabelen van de koolmeesjes horen bij elkaar. Van elk meesje in
de dataset zijn zowel de massa als de spanwijdte gemeten. De dataset is
zo geordend dat als je het n-de punt uit de
\textbf{\passthrough{\lstinline!m\_km!}}-lijst bij het n-de punt uit de
\textbf{\passthrough{\lstinline!span\_km!}}-lijst hoort. Dit zijn de
gegevens van het n-de meesje. Pas dus op dat je de lijsten in de juiste
volgorde houdt! Voor de twee variabelen van de pimpelmeesjes geldt
precies hetzelfde.

We gaan eerst naar de twee massaverdelingen van de meesjes kijken.

\begin{quote}
\begin{itemize}
\item
  \textbf{M2.2a) Plot de massaverdelingen van beide meesjes in een
  histogram. Laat in een legenda zien welke meesje bij welke kleur
  hoort. Maak ook een apart histogram waarin je spanwijdtes van de twee
  soorten meesjes plot. Maak de twee histogrammen netjes af en zorg dat
  duidelijk is welke distributie bij welk soort meesje
  hoort.}\newline\newline TIP: Gebruik de plot optie
  \textbf{\passthrough{\lstinline!alpha=0.8!}} zodat je histogrammen wat
  doorzichtig worden. Zo kan je het achterste histogram ook nog altijd
  goed zien.\newline\newline
\item
  \textbf{M2.2b) Maak een tabel waarin je voor beide soorten meesjes de
  gemiddeldes, de standaarddeviaties en de varianties noteert. Let goed
  op de notatie en denk ook even aan de eenheden.}
\end{itemize}
\end{quote}

We meten nu de massa op van het meesje dat je gevonden hebt. Gebruik de
volgende regel code om dat te doen:

\begin{lstlisting}
    mees_m_laag, mees_m_hoog = ds.meetMassaMeesje()
    
\end{lstlisting}

Je krijgt nu een onderwaarde
\textbf{\passthrough{\lstinline!mees\_m\_laag!}} en een bovenwaarde
\textbf{\passthrough{\lstinline!mees\_m\_hoog!}} terug. Deze geven de
onzekerheid op de meting aan. Het gemiddelde van deze twee is de gemeten
massa, de centrale waarde. De waarde van de massa van de mees ligt
\textbf{zeker} tussen de boven- en onderwaarde in. NB. Als je een
foutmelding krijgt dat
\textbf{\passthrough{\lstinline!meetMassaMeesje()!}} niet bestaat
controleer dan of je wel een nieuwe
\textbf{\passthrough{\lstinline!DAS\_DatasetGenerator.py!}} hebt
downgeload voor Module 2.

Met deze informatie kunnen we nu met de Frequentist Methode de kans
uitrekenen dat onze mees een Koolmeesje is.

\begin{quote}
\begin{itemize}
\item
  \textbf{M2.2c) Gebruik de dataset \passthrough{\lstinline!m\_km!} om
  de kans uit te rekenen dat je een koolmeesje vindt die een massa heeft
  die in het gebied \passthrough{\lstinline!mees\_m\_laag!} en
  \passthrough{\lstinline!mees\_m\_hoog!} in ligt. Dit noem je ook wel
  de voorwaardelijke kans
  \[P(\text{mees_m_hoog < m < mees_m_laag} \mid \text{koolmees})\]. Voor
  het gemak noteren we dit even als
  \[P(m_{\text{obs}} \mid \text{koolmees} )\]. Herhaal dit voor het
  pimpelmeesje, bereken dus ook
  \[P(m_{\text{obs}} \mid \text{pimpelmees} )\].}
\item
  \textbf{M2.2d) Als je kijkt naar de uitkomst van M2.2c), wat vogeltje
  denk je dan dat het is?}
\end{itemize}
\end{quote}

De frequentist methode, zoals we die hierboven gebruiken, is
uiteindelijk een ratio tussen twee getallen. Deze twee getallen hebben
een onzekerheid volgens de Poisson verdeling.

\begin{quote}
\begin{itemize}
\tightlist
\item
  \textbf{M2.2e) Schrijf de formule uit hoe de onzekerheden van de
  noemen en deler zich propageren naar de onzekerheid op de uitgerekende
  kans. Noteer deze formule en bereken met behulp van deze formule de
  onzekerheden uit op de kansen die je in M2.2c) hebt berekend.}
\end{itemize}
\end{quote}

Je besluit ook de spanwijdte van de mees op te meten. Misschien geeft
dat wel meer uitsluitsel.

\begin{lstlisting}
    mees_span_laag, mees_span_hoog = ds.meetLengteMeesje()
    
\end{lstlisting}

De output volgt dezelfde logica als hiervoor.

\begin{quote}
\begin{itemize}
\item
  \textbf{M2.2f) Gebruik dezelfde methode als hiervoor om beide kansen
  \[ P(w_{\text{obs}} \mid \text{koolmees} )\] en
  \[P(w_{\text{obs}} \mid \text{pimpelmees} )\] uit te rekenen maar nu
  door (alleen) gebruik te maken van de informatie van de spanwijdtes.
  Noteer ook de onzekerheden op de uitgerekende kansen.}\newline\newline
\item
  \textbf{M2.2g) Op basis van deze informatie, wat denk je nu dat het
  voor vogeltje is?}
\end{itemize}
\end{quote}

We kunnen nu natuurlijk ook de gecombineerde informatie gebruiken.
Hiervoor gaan we eerst de data visualiseren.

\begin{quote}
\begin{itemize}
\tightlist
\item
  \textbf{M2.2h) Maak een tweedimensionale scatterplot die de
  tweedimensionale dataset van de massa versus de spanwijdte voor zowel
  de pimpelmezen als de koolmezen.}\\
  \textbf{TIP} gebruik de opties
  \textbf{\passthrough{\lstinline!'o',markersize=3, alpha=0.4!}} in de
  plot functie. Zorg dat beide datasets weer hun eigen kleur hebben en
  vergeet de legenda niet.
\end{itemize}
\end{quote}

Het valt misschien op dat er een verband lijkt te zijn tussen beide
variabelen. We gaan daar eerst naar kijken naar
\href{/module-2/meerdimensionale-data}{de covariantie} en de correlatie
tussen de massa en de spanwijdte voor beide vogelsoorten.

\begin{quote}
\begin{itemize}
\item
  \textbf{M2.2i) Bereken de covariantie en de correlatie tussen de massa
  en de spanwijdte voor zowel de koolmeesje als de pimpelmeesjes
  meetgegevens.}\newline\newline
\item
  \textbf{M2.2j) Als je naar de berekende correlaties kijkt wat valt dan
  op, wat voor verband zit er tussen de twee variabelen? Als je toch
  even als een Bioloog nadenkt, is dit dan wat je
  verwacht?}\newline\newline
\end{itemize}
\end{quote}

We gaan terug naar de kansberekeningen.

\begin{quote}
\begin{itemize}
\tightlist
\item
  \textbf{M2.2k) Combineer nu de gegevens en bereken de kansen
  \[{P(m_{\text{obs}}\text{ en }w_{\text{obs}} \mid \text{koolmees})}\]
  en
  \[{P(m_{\text{obs}}\text{ en }w_{\text{obs}} \mid \text{pimpelmees})}\].}\newline\newline
\item
  \textbf{M2.2l) Welk vogeltje denk je nu dat het is? Beredeneer je
  antwoord.}
\end{itemize}
\end{quote}

Na al deze berekeningen lopen we een eindje in de tuin. Op de plek waar
we eerder het meesje aantroffen zit nu een ander meesje hartstochtelijk
te zingen. Aan de zang hoor je direct dat dit een pimpelmeesje is. Je
schat in dat er een kans is van 90\% dat dit pimpelmeesje bij het andere
meesje hoorde, en dat dat dus ook een pimpelmees is.

\begin{quote}
\begin{itemize}
\tightlist
\item
  \textbf{M2.2m) Bereken nu de kans dat het inderdaad een pimpelmeesje
  is geweest:
  \[P(\text{pimpelmees} \mid m_\text{obs} \text{ en } w_{\text{obs}}).\]
  Bereken hier alleen de centrale waarde.}\\
  TIP: Maak hierbij gebruik van de
  \href{/module-2/extra-kansrekenregels}{vergelijking} van Bayes. Om
  \[P(m_\text{obs} \text{ en }w_{\text{obs}})\] te berekenen kun je
  gebruiken maken van de volgende formule:
  \[P(C) = P(C \mid D)\cdot P(D) + P(C \mid \text{niet }D)\cdot P(\text{niet }D)\]
  .
\end{itemize}
\end{quote}

\hypertarget{m2.3-halfwaardedikte-ii}{%
\section{M2.3 Halfwaardedikte II ***}\label{m2.3-halfwaardedikte-ii}}

We gaan nu terug naar het experiment uit opgave M1.5 waarbij we de
halfwaardedikte van lood onderzoeken bij een bepaalde gamma-bron. We
gaan de onzekerheid op het meetresultaat, \[d_{half}\] onderzoeken.

In opgave M1.5 gebruikten we een methode om de halfwaardedikte te
bepalen waarbij we steeds de ratio tussen het aantal counts zonder lood
\[N_0\] en een waarde met lood \[N_{half}\] uitrekende. Zodra deze ratio
onder de 0.5 komt nemen we \[x\] als de halfwaardedikte.

\begin{quote}
\begin{itemize}
\tightlist
\item
  \textbf{M2.3a) Wat is de onzekerheid op de ratio R? Bereken deze door
  gebruik te maken van de onzekerheden op \[N_0\] en \[N_{half}\] en de
  regels voor propagatie van ongecorreleerde fouten
  (\href{/module-2/foutenpropagatiei}{Deze kan je hier vinden}). Schrijf
  je berekening helemaal uit.}
\end{itemize}
\end{quote}

Een \textbf{schatter} is een recept om de waarde van een parameter af te
schatten. De parameter die we hier willen bepalen is de halwaardedikte
van lood (voor de energie van onze bron). De schatter is in dit geval
\[d_{half}\].

Nu gaan we het experiment 50 keer herhalen en gaan we kijken naar de
distributie van de gevonden halfwaardediktes. We gaan uit deze
distributie de standaarddeviatie halen en dit gebruiken om de
onzekerheid op de gevonden dikte \[d_{half}\] te bepalen.

Schrijf een loop waarin je 50x een nieuwe dataset genereert waaruit je
50x opnieuw een halfwaardedikte bepaald. Om 50 unieke dataset te maken
moet je steeds de zogeheten \textbf{\emph{seed}} veranderen. Dat kan je
doen door een seed mee te geven aan de DAS dataset generator:

\begin{lstlisting}
for j in range(0,50) :
    counts, diktes = ds.DataSetHalfwaardeDikte(j)
\end{lstlisting}

Binnen deze loop maak je 50 unieke datasets aan waarbij de counts die
gemeten worden steeds worden gevarieerd volgens de Poisson statistiek.

\begin{quote}
\begin{itemize}
\item
  \textbf{M2.3b) Maak een histogram waarin je de gevonden
  halfwaardediktes van de 50 verschillende experimenten laat zien. Zorg
  dat het histogram de distributie netjes laat zien en dat de as-labels
  goed zijn aangemaakt.}\newline \textbf{TIP:} de binning in het
  histogram luistert nauw doordat er alleen bepaalde uitkomsten van de
  halfwaardedikte mogelijk zijn. Reken precies uit wat de range en de
  binning moet zijn in het histogram om te voorkomen dat je lege bins
  midden in de distributie krijgt. \newline\newline
\item
  \textbf{M2.3c) Ziet de distributie eruit zoals je verwacht had?
  Beredeneer je antwoord.}\newline\newline
\item
  \textbf{M2.3d) Bepaal nu het gemiddelde van de meetuitkomsten en de
  standaarddeviatie van de distributie.} \newline\newline
\item
  \textbf{M2.3e) Zeggen deze getallen ook iets of de gemeten waardes
  gemiddeld te hoog of te laag uitkomen. Beredeneer je antwoord.}
\end{itemize}
\end{quote}

We gaan nu kijken hoe zuiver de meting is. De onzuiverheid is
gedefinieerd als het verschil tussen de echte waarde en de gemiddelde
gemeten waarde. Bij gesimuleerde data kunnen we dit onderzoeken, daarvan
kunnen we het meetresultaat vergelijken met de initiÃ«le waardes die we
hebben gebruikt in de simulatie.

Om de zuiverheid van ons experiment te bepalen gaan we dus de bepaalde
halfwaardedikte te vergelijken met de initiÃ«le halfwaardedikte die
gebruikt is om de data te simuleren. Roep hiervoor de volgende functie
aan in de dataset generator:

\begin{lstlisting}
metingen, diktes, d_true = ds.DataSetHalfwaardeDikteVariatie(s,d_input)
\end{lstlisting}

Je geeft twee variabelen mee aan de functie: de seed
(\textbf{\passthrough{\lstinline!s!}}) en een
waarde(\textbf{\passthrough{\lstinline!d\_input!}}). We komen er zo op
terug wat deze variabelen betekenen. De functie geeft drie objecten
terug. De eerste twee zijn de lists met de counts en de looddikte (zoals
je eerder ook terugkreeg), de derde variabele is halfwaardedikte die
gebruikt is als input voor de simulatie. Dit noemen we meestal de
\emph{true} waarde in simulaties vandaar dat we hem
\textbf{\passthrough{\lstinline!d\_true!}} noemen. Met de variabele
\textbf{\passthrough{\lstinline!d\_input!}} kunnen we nu de input waarde
van de simulatie controleren. In principe is
\textbf{\passthrough{\lstinline!d\_input!}} gelijk aan
\textbf{\passthrough{\lstinline!d\_true!}}, tenzij je de waarde -1
kiest.

Met deze dataset generator gaan we nu de zuiverheid van onze meting
bestuderen.

\begin{quote}
\begin{itemize}
\item
  Kijk eerste eens naar wat de \emph{true} waarde was in je datasets die
  je hierboven hebt gebruikt! Als je voor
  \textbf{\passthrough{\lstinline!d\_input!}} nu -1 invult krijg je de
  halfwaardedikte die gebruikt is voor het genereren van de 50 datasets
  die je eerder in deze opdracht hebt gebruikt. \newline\newline
\item
  \textbf{M2.3f) Hoe groot is de onzuiverheid van ons experiment?
  Vergelijk hiervoor de gemiddelde bepaalde halfwaardediktes van de 50
  experimenten met de \passthrough{\lstinline!d\_true!}.}
\end{itemize}
\end{quote}

Nu kun je het gedrag bekijken over meerdere waardes rond de
\textbf{\passthrough{\lstinline!d\_true!}} waarde. Plaats een grote loop
over je hele code en varieer de
\textbf{\passthrough{\lstinline!d\_input!}} waarde bijvoorbeeld met 5 of
10 procent rond je aanvankelijke waarde. Voor elke setting van
\textbf{\passthrough{\lstinline!d\_input!}} bepaal je over 50
experimenten het gemiddelde van de bepaalde waardes van
\[\text{d}_{\text{half}}\].

\begin{quote}
\begin{itemize}
\item
  \textbf{M2.3g) Zet de gevonden gemiddelde waardes zet je in een
  grafiek uit tegen de gekozen waardes
  van\passthrough{\lstinline!d\_input!}. Let goed op de leesbaarheid van
  je grafiek en zorg dat je makkelijk kunt aflezen waar de zuivere
  meting zou liggen (dus als d\_half = d\_input).}\newline\newline
\item
  \textbf{M2.3h) Is de onzuiverheid altijd constant of varieert die
  afhankelijk van de halfwaardedikte?}\newline\newline
\item
  \textbf{M2.3i) In dit geval simuleren we het experiment. Zou je een
  methode kunnen bedenken om de onzuiverheid van je experiment te
  onderzoeken bij een echte meting?}
\end{itemize}
\end{quote}

\hypertarget{opgaves-bij-module-2}{%
\chapter{Opgaves bij Module 2}\label{opgaves-bij-module-2}}

Lees goed het \href{/tussentoets-ii/inhoud}{lijstje} door ter
voorbereiding voor de tussentoets. Niet voor alle element op het lijstje
zijn oefenopgaves.

\textbf{Let op:} Voor alle opgaven in dit vak geldt dat je bij het
noteren van resultaten je moet houden aan de regels. Kijk hiervoor goed
naar het stukje `significantie en notatie' in het hoofdstuk
\href{/module-1/notatie}{Notatie}.

\hypertarget{foutenpropagatie-1}{%
\section{Foutenpropagatie}\label{foutenpropagatie-1}}

\textbf{1.} Als \[y = 2 x + 0.6\] en de fout op \[x\] is \[\Delta x\],
wat is dan de fout op \[y\]? \newline\newline \emph{\textbf{Antwoord:}
\[{\displaystyle \Delta y = \sqrt{\left(\frac{\partial y}{\partial x}\right)^2 (\Delta x)^2 } = \sqrt{4 (\Delta x)^2}=2\Delta x}\]}\newline

\begin{center}\rule{0.5\linewidth}{\linethickness}\end{center}

\textbf{2.} Als \[y = -3 x + 2  x^2\] en de fout op \[x\] is
\[\Delta x\], wat is dan de fout op \[y\]? \newline\newline
\emph{\textbf{Antwoord:}
\[{\displaystyle \Delta y = \sqrt{\left(\frac{\partial y}{\partial x}\right)^2 (\Delta x)^2 } = \sqrt{(-3+4x)^2 (\Delta x)^2}= |{-3+4x}| \cdot \Delta x}.\]}\newline

\begin{center}\rule{0.5\linewidth}{\linethickness}\end{center}

\textbf{3.} Als \[y = \sin(x)\] en de fout op \[x\] is \[\Delta x\], wat
is dan de fout op \[y\]? \newline\newline \emph{\textbf{Antwoord:}
\[{\displaystyle \Delta y = \sqrt{\left(\frac{\partial y}{\partial x}\right)^2 (\Delta x)^2 } = \sqrt{(\cos x)^2 (\Delta x)^2}= \cos x \cdot \Delta x}.\]}\newline

\begin{longtable}[]{@{}l@{}}
\toprule
\begin{minipage}[b]{0.07\columnwidth}\raggedright
\textbf{4.} Als \[y = \frac{1}{x^2}\] en de fout op \[x\] is
\[\Delta x\], wat is dan de fout op \[y\]? \newline\newline
\emph{\textbf{Antwoord:}
\[{\displaystyle \Delta y = \sqrt{\left(\frac{\partial y}{\partial x}\right)^2 (\Delta x)^2 } = \sqrt{\left( -\frac{2}{x^3} \right)^2 (\Delta x)^2}= \frac{2}{x^3} \cdot \Delta x}.\]}\newline\strut
\end{minipage}\tabularnewline
\midrule
\endhead
\begin{minipage}[t]{0.07\columnwidth}\raggedright
\textbf{5.} Als \[E = mc^2\] en de fouten op (\[m\],\[c\]) zijn
(\[\Delta m\],\[\Delta c\]), wat is dan de fout op \[E\]?
\newline\newline \emph{\textbf{Antwoord:}
\[{\displaystyle \Delta E = \sqrt{\left(\frac{\partial E}{\partial m}\right)^2 (\Delta m)^2 + \left(\frac{\partial E}{\partial c}\right)^2 (\Delta c)^2 } = \sqrt{(c)^2(\Delta m)^2 + (2mc)^2 (\Delta c)^2}}.\]}\strut
\end{minipage}\tabularnewline
\bottomrule
\end{longtable}

\textbf{6.} Als \[E = mc^2\] en de fouten op (\[m\],\[c\]) zijn
(\[\Delta m\],\[\Delta c\]), wat is dan de fout op
\[E\]?\newline\newline \emph{\textbf{Antwoord:}
\[{\displaystyle \Delta E = \sqrt{\left(\frac{\partial E}{\partial m}\right)^2 (\Delta m)^2 + \left(\frac{\partial E}{\partial c}\right)^2 (\Delta c)^2 } = \sqrt{(c)^2(\Delta m)^2 + (2mc)^2 (\Delta c)^2}}.\]}

\begin{longtable}[]{@{}l@{}}
\toprule
\endhead
\begin{minipage}[t]{0.07\columnwidth}\raggedright
\textbf{7.} Stel je wil de kinetische energie berekenen van een object.
De formule is \[E_k = 1/2 m \cdot v^2\]. Je meet de massa van het
object, deze is \[m=2.3 \pm 0.2\] kg. De snelheid is \[v=0.20 \pm 0.05\]
m/s. \newline Bereken de kinetische energie.\newline
\emph{\textbf{Antwoord:}
\[\displaystyle{E_k = 1/2 m \cdot v^2 = 0.046}\] J\newline
\begin{equation}\displaystyle{ \Delta E_k = \sqrt{\left(\frac{\partial E_k}{\partial m}\right)^2 \left( \Delta m\right)^2 + \left(\frac{\partial E_k}{\partial v}\right)^2 \left( \Delta v \right)^2} = \sqrt{\left( \frac{1}{2}v^2 \Delta m\right)^2 + \left( mv \Delta m \right)^2 } = 0.02}\end{equation}\newline
\begin{equation}E_k =  0.046 \pm 0.02\end{equation} J}\strut
\end{minipage}\tabularnewline
\begin{minipage}[t]{0.07\columnwidth}\raggedright
\#\# De Wet van Grote aantallen\strut
\end{minipage}\tabularnewline
\begin{minipage}[t]{0.07\columnwidth}\raggedright
\textbf{8.} We hebben een dataset met de gemeten massa van 80 kogels.
Het gemiddelde van de massa-distributie is bepaald op 108.2 kg. De
standaarddeviatie van de massa-distributie is 11.2 kg. Wat is de fout op
het berekende gemiddelde?\newline \emph{\textbf{Antwoord:} De fout
(onzekerheid) op het bepaalde gemiddelde is gelijk aan:\newline
\begin{equation}{\displaystyle \Delta \mu = \frac{\sigma}{\sqrt{N}} = \frac{11.2}{\sqrt{80}}} \text{ kg} = 1.25\text{ kg}\end{equation}}\strut
\end{minipage}\tabularnewline
\bottomrule
\end{longtable}

\textbf{9.} We combineren onafhankelijke datasets waarbij de spanwijdte
van koolmeesjes zijn gemeten. Dataset A heeft informatie over 1100
koolmeesjes met een gemiddelde spanwijdte van 13.4 cm met een
standaarddeviatie van 2.0 cm. Dataset B heeft informatie over 2000
koolmeesjes met gemiddelde van 14.0 cm en een standaarddeviatie van 1.8
cm.\newline Wat is het gemiddelde van de gecombineerde dataset
T?\newline \emph{\textbf{Antwoord:}
\[{\displaystyle \mu_A = \sum_a^{N_A=1100} \frac{x_a}{N_A} \text{ en } \mu_B = \sum_b^{N_B=2000} \frac{x_b}{N_B} \text{ ook geldt: }  \mu_T = \frac{\sum^{N_A} x_a + \sum^{N_B} x_b}{N_T}}\]\newline
\begin{equation}{\displaystyle \mu_T =  \frac{N_A \cdot \mu_A + N_B \cdot \mu_B}{N_A + N_B}} = 13.8 \text{ kg}\end{equation}}\newline

\begin{longtable}[]{@{}l@{}}
\toprule
\endhead
\begin{minipage}[t]{0.07\columnwidth}\raggedright
\textbf{10.} Onder welke voorwaarde mogen we aannemen dat de onzekerheid
op het berekende gemiddelde van een dataset kleiner wordt als we
datapunten toevoegen?\newline \emph{\textbf{Antwoord:} Dat mogen we doen
als voor de onderliggende verdeling van de dataset een goed
gedefinieerde variantie bestaat.}\strut
\end{minipage}\tabularnewline
\bottomrule
\end{longtable}

\textbf{11.} We hebben een dataset met metingen van een grootheid \[x\]
met precies 16 punten. Het gemiddelde waarde van \[\mu = 22\] met een
standaarddeviatie van \[\sigma = 4 \]. \newline \textbf{a.} Wat is de
onzekerheid op het gemiddelde van deze dataset?\newline
\emph{\textbf{Antwoord:} De onzekerheid is:
\[\sigma_\mu (=\Delta \mu)= \frac{\sigma}{\sqrt{N}} = 4/\sqrt{16} = 1 \]}\newline
\textbf{b.} We voegen nog 9 extra waardes aan onze dataset toe. Wat is
de onzekerheid op het gemiddelde nu?\newline \emph{\textbf{Antwoord:} De
onzekerheid is:
\[\sigma_\mu (=\Delta \mu)= \frac{\sigma}{\sqrt{N}} = 4/\sqrt{25} = 0.8 \]}\newline

\hypertarget{meerdimensionale-data}{%
\section{Meerdimensionale data}\label{meerdimensionale-data}}

\textbf{12.} Je hebt de volgende dataset met waardes van x en y:
\newline

\{2,5\}, \{1,4\}, \{5,2\}, \{3,0\}

\newline

\textbf{a.} Bereken de covariantie.\newline \emph{\textbf{Antwoord:}
\[<{x}>= (2+1+5+3)/4 = 2.75\] \newline
\begin{equation}<{y}>= (5+4+2+0)/4 = 2.75\end{equation}\newline
\begin{equation}\text{cov}(xy) = \frac{1}{n} \sum_n (x_i-<{x}>)\cdot (y_i - <{y}>) = \end{equation}\newline
\begin{equation}\frac{1}{4}\times\left((2-2.75)\cdot(5-2.75) +(1-2.75)\cdot(4-2.75)+(5-2.75)\cdot(2-2.75) + (3-2.75)\cdot(0-2.75)\right) \end{equation}
\newline \begin{equation} = -1.6\end{equation}}\newline \textbf{b.}
Bereken de correlatie.\newline \emph{\textbf{Antwoord:}
\[\sigma_x^2 = <{x^2}>-<{x}>^2 = (4+1+25+9)/4 - 2.75^2 = 2.1875\]
\newline
\begin{equation}\sigma_y^2 = <{y^2}>-<{y}>^2 = (25+16+4+0)/4 - 2.75^2 = 3.6875\end{equation}
\newline \begin{equation}\sigma_x = 1.48\end{equation},
\[\sigma_y = 1.48\]
\begin{equation}\rho = \frac{\text{cov}_{xy}}{\sigma_x \sigma_y} = \frac{-1.56}{1.48\times 1.92} = -0.55\end{equation}}\newline

\begin{center}\rule{0.5\linewidth}{\linethickness}\end{center}

\textbf{13.} Je hebt de volgende dataset met waardes van x en y:
\newline

\{1,0\}, \{3,4\}, \{2,6\}, \{4,8\}

\newline

\textbf{a.} Bereken de covariantie.\newline \emph{\textbf{Antwoord:}
\[<{x}>= 2.5\] \newline \begin{equation}<{y}>= 4.5\end{equation}\newline
\begin{equation}\text{cov}(xy) = \frac{1}{n} \sum_n (x_i-<{x}>)\cdot (y_i - <{y}>) = 2.75\end{equation}\newline*\newline
\textbf{b.} Bereken de correlatie.\newline }\textbf{Antwoord:}
\[\sigma_x^2 = <{x^2}>-<{x}>^2 = 1.118^2\]\newline
\begin{equation}\sigma_y^2 = <{y^2}>-<{y}>^2 = 2.958^2\end{equation}\newline
\begin{equation}\rho = \frac{\text{cov}_{xy}}{\sigma_x \sigma_y} = \frac{2.75}{1.118\times 2.958} = 0.83\end{equation}*\newline

\hypertarget{extra-kansrekenregels}{%
\section{Extra kansrekenregels}\label{extra-kansrekenregels}}

\textbf{14.} Op een zomerse avond zie je rook en waar rook is is vuur.
Op een zomerse avond is de kans dat je rook ziet (10\%), meestal door
gebruik van barbeques. Gevaarlijke branden zijn heel zeldzaam (1\%) de
kans dat rook bij een gevaarlijke brand vrijkomt is groot (90\%). Wat is
de kans dat de rook die je ziet van een een gevaarlijk brand
afkomt?\newline

*\textbf{Antwoord:} Gebruik Bayes theorema om dit uit te
rekenen.\newline
\begin{equation}{\displaystyle \text{P(gevaarlijke brand|rook)} = \frac{\text{P(rook|gevaarlijke brand)}\cdot{\text{P(gevaarlijke brand)}}}{\text{P(rook)}} = \frac{0.9 \times 0.01}{0.10} = 0.09}\end{equation}\newline*

\end{document}
